{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSlUM6tNGp1c"
      },
      "outputs": [],
      "source": [
        "# Public Score : 0.1951219512195122\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Constants\n",
        "ROOT_DIR = \"data\"\n",
        "RANDOM_STATE = 110\n",
        "N_FEATURES_TO_SELECT = 160\n",
        "\n",
        "# 데이터 로드\n",
        "train_data = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))\n",
        "test_data = pd.read_csv(os.path.join(ROOT_DIR, \"test.csv\"))\n",
        "\n",
        "# NaN 열 제거\n",
        "train_data.drop(columns=train_data.columns[train_data.isna().all()], inplace=True)\n",
        "test_data.drop(columns=test_data.columns[test_data.isna().all()], inplace=True)\n",
        "\n",
        "# Set_ID 열 제거\n",
        "test_data.drop(columns=['Set_ID'], inplace=True, errors='ignore')\n",
        "\n",
        "# 문자열 데이터 인코딩\n",
        "non_numeric_columns = train_data.select_dtypes(include=['object']).columns.tolist()\n",
        "if 'target' in non_numeric_columns:\n",
        "    non_numeric_columns.remove('target')\n",
        "\n",
        "label_encoders = {col: LabelEncoder().fit(pd.concat([train_data[col], test_data[col]], axis=0))\n",
        "                  for col in non_numeric_columns}\n",
        "\n",
        "for column, encoder in label_encoders.items():\n",
        "    train_data[column] = encoder.transform(train_data[column])\n",
        "    test_data[column] = encoder.transform(test_data[column])\n",
        "\n",
        "# 타겟 변환\n",
        "train_data[\"target\"] = train_data[\"target\"].map({'Normal': 0, 'AbNormal': 1})\n",
        "\n",
        "# 파생 변수 생성\n",
        "def create_features(data):\n",
        "    data['position_x_diff'] = data['CURE END POSITION X Collect Result_Dam'] - data['CURE START POSITION X Collect Result_Dam']\n",
        "    data['position_z_diff'] = data['CURE END POSITION Z Collect Result_Dam'] - data['CURE START POSITION Z Collect Result_Dam']\n",
        "    data['judge_diff'] = data['Insp Judge Code_Dam'].apply(lambda x: 1 if x == 'OK' else 0)\n",
        "    data['position_ratio_xz'] = data['CURE END POSITION X Collect Result_Dam'] / (data['CURE END POSITION Z Collect Result_Dam'] + 1)\n",
        "    data['position_theta_diff'] = data['CURE END POSITION Θ Collect Result_Dam'] - data['CURE START POSITION Θ Collect Result_Dam']\n",
        "\n",
        "    for col in ['CURE END POSITION X Collect Result_Dam',\n",
        "                 'CURE END POSITION Z Collect Result_Dam',\n",
        "                 'CURE END POSITION Θ Collect Result_Dam']:\n",
        "        data[f'{col}_log'] = np.log1p(data[col] - data[col].min() + 1)\n",
        "        data[f'{col}_sqrt'] = np.sqrt(data[col] - data[col].min() + 1)\n",
        "\n",
        "\n",
        "\n",
        "create_features(train_data)\n",
        "create_features(test_data)\n",
        "\n",
        "# 특징과 타겟 분리\n",
        "features = [col for col in train_data.columns if col != 'target']\n",
        "train_x = train_data[features]\n",
        "train_y = train_data[\"target\"]\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "\n",
        "# RFE로 피처 선택\n",
        "base_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "rfe_selector = RFE(base_model, n_features_to_select=N_FEATURES_TO_SELECT, step=1)\n",
        "rfe_selector.fit(train_x, train_y)\n",
        "train_x_rfe = train_x[:, rfe_selector.support_]\n",
        "\n",
        "# Train-validation split\n",
        "train_x_rfe, val_x_rfe, train_y, val_y = train_test_split(train_x_rfe, train_y, test_size=0.3, random_state=RANDOM_STATE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=train_y)\n",
        "\n",
        "# 개별 모델 설정\n",
        "catboost_model = CatBoostClassifier(iterations=700, depth=10, learning_rate=0.02,\n",
        "                                    loss_function='Logloss', eval_metric='F1',\n",
        "                                    class_weights=class_weights, random_state=RANDOM_STATE, silent=True, l2_leaf_reg=5)\n",
        "\n",
        "xgb_model = XGBClassifier(scale_pos_weight=class_weights[1], reg_alpha=0.1, reg_lambda=1.0, random_state=RANDOM_STATE)\n",
        "lgb_model = LGBMClassifier(scale_pos_weight=class_weights[1], lambda_l1=0.1, lambda_l2=1.0, random_state=RANDOM_STATE)\n",
        "logistic_model = LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE)\n",
        "\n",
        "# 앙상블 구성\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "    ('catboost', catboost_model),\n",
        "    ('xgb', xgb_model),\n",
        "    ('lgb', lgb_model),\n",
        "    ('logistic', logistic_model)],\n",
        "    voting='soft', weights=[2, 1.5, 1.5, 1])\n",
        "\n",
        "# 앙상블 모델 학습 및 평가\n",
        "ensemble_model.fit(train_x_rfe, train_y)\n",
        "val_pred_ensemble = ensemble_model.predict(val_x_rfe)\n",
        "f1_ensemble = f1_score(val_y, val_pred_ensemble)\n",
        "print(f\"Ensemble Validation F1 Score: {f1_ensemble}\")\n",
        "\n",
        "# 테스트 데이터 전처리 및 예측\n",
        "test_x = test_data[features]\n",
        "test_x = scaler.transform(test_x)\n",
        "test_x_rfe = test_x[:, rfe_selector.support_]\n",
        "test_pred_ensemble = ensemble_model.predict(test_x_rfe)\n",
        "\n",
        "# 결과를 submission.csv에 저장\n",
        "submission = pd.read_csv(\"submission.csv\")\n",
        "submission[\"target\"] = ['Normal' if pred == 0 else 'AbNormal' for pred in test_pred_ensemble]\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to submission.csv\")\n"
      ]
    }
  ]
}